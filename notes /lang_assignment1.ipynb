{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the command line, first make sure to run the setup script to install requirements:\n",
    "\n",
    "```shell \n",
    "bash setup.sh\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop over each text file in \"in\" folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# creating a function to clean each text - *** might be issue with this cleaning ***\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    A function to clean each text making it easier and limiting issues later\n",
    "    Args:\n",
    "        text (string): Cleaning the texts, replacing the \\n - new lines and \\t - tabs and the text between the <> characters with just a character of white space \n",
    "\n",
    "    Returns:\n",
    "        text (string): the cleaned text  \n",
    "    \"\"\"\n",
    "    text = re.sub(\"[\\n\\t]\", \" \", text)\n",
    "    text = re.sub(\"<.*?>\", \" \", text)\n",
    "    return text \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the relative frequency of Nouns, Verbs, Adjective, and Adverbs per 10,000 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rel_freq(doc):\n",
    "    \"\"\" Finds the relative frequencies of specified parts of speech (POS) \n",
    "\n",
    "    Args:\n",
    "        doc (nlp object):\n",
    "        Creating a counter for each POS\n",
    "        For loop which will add 1 to each counter for the specified POS \n",
    "        Calculating the relative frequency per 10,000 words, rounding it to 2 decimals points for ease \n",
    "    Returns:\n",
    "        _type_(float): four floats \n",
    "    \"\"\" \n",
    "    noun_count = 0\n",
    "    verb_count = 0\n",
    "    adjective_count = 0\n",
    "    adverb_count = 0\n",
    "    for token in doc:\n",
    "        if token.pos_ == \"NOUN\":\n",
    "            noun_count +=1\n",
    "        if token.pos_ == \"VERB\":\n",
    "            verb_count +=1\n",
    "        if token.pos_ == \"ADJ\":\n",
    "            adjective_count +=1\n",
    "        if token.pos_ == \"ADV\":\n",
    "            adverb_count +=1\n",
    "    relative_freq_n = round((noun_count/len(doc)) * 10000,2)\n",
    "    relative_freq_v = round((verb_count/len(doc)) * 10000, 2)\n",
    "    relative_freq_adj = round((adjective_count/len(doc)) * 10000, 2)\n",
    "    relative_freq_adv = round((adverb_count/len(doc)) * 10000, 2)\n",
    "    return relative_freq_n, relative_freq_v, relative_freq_adj, relative_freq_adv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find the total number of *unique* PER, LOC, ORGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique_ent(doc): \n",
    "    \"\"\"\n",
    "    Calculates the amount of unique entities in an nlp object\n",
    "    Args:\n",
    "        doc (nlp object): creates an empty list\n",
    "        for each of the three entities, adds them to their specified list\n",
    "        counts the total of unique entities of each type specified \n",
    "\n",
    "    Returns:\n",
    "        doc (nlp object): integers for each entity type \n",
    "    \"\"\"\n",
    "    person = []\n",
    "    loc = []\n",
    "    orgs = []\n",
    " \n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ == \"PERSON\":\n",
    "            person.append(ent.text)\n",
    "        if ent.label_ == \"LOC\":\n",
    "            loc.append(ent.text)\n",
    "        if ent.label_ == \"ORG\":\n",
    "            orgs.append(ent.text)\n",
    "    # give the unique NER per each category \n",
    "    unique_person_count = len(set(person))\n",
    "    unique_loc_count = len(set(loc))\n",
    "    unique_orgs_count = len(set(orgs))\n",
    "    return unique_person_count, unique_loc_count, unique_orgs_count\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "path = os.path.join(\"..\", \"in\", \"USEcorpus\")\n",
    "dir = os.listdir(path)\n",
    "\n",
    "for folder in dir:\n",
    "    # going into every folder within the USEcorpus directory \n",
    "    folder_path = os.path.join(\"..\", \"in\", \"USEcorpus\", f'{folder}') \n",
    "    # saves the list of all files and directories in the path we just named above \n",
    "    folder_dir = os.listdir(folder_path)\n",
    "    # making a large empty dataframe with the columns specified  \n",
    "    df = pd.DataFrame(columns=[\"Filename\", \"RelFreq NOUN\", \"RelFreq VERB\", \"RelFreq ADJ\", \"RelFreq ADV\", \"Unique PERSON\", \"Unique LOC\", \"Unique ORG\"])\n",
    "    # for loop of what to do with each file using the above functions \n",
    "    for file in folder_dir:\n",
    "        # selelcting each file in each folder \n",
    "        file_path = folder_path = os.path.join(\"..\", \"in\", \"USEcorpus\", f'{folder}', f'{file}') \n",
    "        # reading each file \n",
    "        with open(file_path, \"r\", encoding=\"latin-1\") as f:\n",
    "            raw_text = f.read() \n",
    "        # cleaning function\n",
    "        text = clean_text(raw_text) \n",
    "        # making nlp object\n",
    "        doc = nlp(text)  \n",
    "        # relative frequency function\n",
    "        relative_freq_n, relative_freq_v, relative_freq_adj, relative_freq_adv = rel_freq(doc) \n",
    "        # unique entity function\n",
    "        unique_person_count, unique_loc_count, unique_orgs_count = unique_ent(doc) \n",
    "        # creating a new object with all the variables \n",
    "        new_dat = (file, relative_freq_n, relative_freq_v, relative_freq_adj, relative_freq_adv, unique_person_count, unique_loc_count, unique_orgs_count)\n",
    "        # creating a pandas data frame with the new_dat object we just created for each file to fill \n",
    "        file_df = pd.DataFrame([new_dat],columns=[\"Filename\", \"RelFreq NOUN\", \"RelFreq VERB\", \"RelFreq ADJ\", \"RelFreq ADV\", \"Unique PERSON\", \"Unique LOC\", \"Unique ORG\"])\n",
    "        # concatenating the empty df data frame with the new file_df data frame and assigning it all to the df data frame; ignoring index to avoid issues with indexing them incorrectly \n",
    "        df = pd.concat([df, file_df], ignore_index=True)  \n",
    "    # creating an outpath for each folder \n",
    "    outpath = os.path.join(\"..\", \"out\", f\"{folder}.csv\")\n",
    "    # turning each data frame into a .csv file and saving it to each folder it belongs to \n",
    "    df.to_csv(outpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2 (default, Feb 28 2021, 17:03:44) \n[GCC 10.2.1 20210110]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
